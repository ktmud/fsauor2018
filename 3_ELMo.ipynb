{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook tries out the state-of-the-art word embeding model [ELMo](https://allennlp.org/elmo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from config import validate_data_path, train_data_path, testa_data_path, testb_data_path\n",
    "from fgclassifier import read_csv\n",
    "\n",
    "def content_to_corpus(data_path, txt_path, sample_n=None, print_sample=10):\n",
    "    \"\"\"Convert Review content to text corpus for word embedding training\"\"\"\n",
    "    df = read_csv(data_path, seg_words=True, sample_n=None)\n",
    "    if sample_n:\n",
    "        df = df.sample(sample_n, random_state=1)\n",
    "    sentences = [\n",
    "        y.strip() for x in df['content']\n",
    "        for y in x.strip('\"').split('ã€‚') if y.strip()\n",
    "    ]\n",
    "    if print_sample:\n",
    "        print('\\n'.join(sentences[:print_sample]))\n",
    "    all_content = '\\n'.join(sentences)\n",
    "    with open(txt_path, 'w') as f:\n",
    "        f.write(all_content + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-15 02:38:27,079 [INFO] Read cache data/train/sentiment_analysis_trainingset.csv.segged_sample_None.tsv..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¼å¼ å¼ ï¼Œ èŒæ­» äºº çš„ æ£’æ£’ç³– ï¼Œ ä¸­ äº† å¤§ä¼— ç‚¹è¯„ çš„ éœ¸ç‹é¤ ï¼Œ å¤ª å¯çˆ± äº†\n",
      "ä¸€ç›´ å°± å¥½å¥‡ è¿™ä¸ª æ£’æ£’ç³– æ˜¯ æ€ä¹ˆ ä¸ª ä¸œè¥¿ ï¼Œ å¤§ä¼— ç‚¹è¯„ ç»™ äº† æˆ‘ è¿™ä¸ª åœŸè€å†’ ä¸€ä¸ª è§è¯† çš„ æœºä¼š\n",
      "çœ‹ ä»‹ç» æ£’æ£’ç³– æ˜¯ ç”¨ å¾·å›½ ç³– åš çš„ ï¼Œ ä¸ä¼š å¾ˆç”œ ï¼Œ ä¸­é—´ çš„ ç…§ç‰‡ æ˜¯ ç³¯ç±³ çš„ ï¼Œ èƒ½ é£Ÿç”¨ ï¼Œ çœŸæ˜¯å¤ª é«˜ç«¯ å¤§æ°” ä¸Šæ¡£æ¬¡ äº† ï¼Œ è¿˜ å¯ä»¥ ä¹° è´è¶ç»“ æ‰å£ ï¼Œ é€äºº å¯ä»¥ ä¹° ç¤¼ç›’\n",
      "æˆ‘ æ˜¯ å…ˆ æ‰“ çš„ å–å®¶ ç”µè¯ ï¼Œ åŠ  äº† å¾®ä¿¡ ï¼Œ ç»™ å–å®¶ ä¼  çš„ ç…§ç‰‡\n",
      "ç­‰ äº† å‡ å¤© ï¼Œ å–å®¶ å°± å‘Šè¯‰ æˆ‘ å¯ä»¥ å–è´§ äº† ï¼Œ å» å¤§å®˜ å±¯ é‚£å– çš„\n",
      "è™½ç„¶ è¿ å–å®¶ çš„ é¢ éƒ½ æ²¡ è§åˆ° ï¼Œ ä½†æ˜¯ è¿˜æ˜¯ è°¢è°¢ å–å®¶ é€ æˆ‘ è¿™ä¹ˆ å¯çˆ± çš„ ä¸œè¥¿ ï¼Œ å¤ª å–œæ¬¢ äº† ï¼Œ è¿™ å“ª èˆå¾—åƒ å•Š\n",
      "ç¬¬ä¸‰æ¬¡ å‚åŠ  å¤§ä¼— ç‚¹è¯„ ç½‘ éœ¸ç‹é¤ çš„ æ´»åŠ¨\n",
      "è¿™å®¶ åº— ç»™ äºº æ•´ä½“ æ„Ÿè§‰ ä¸€èˆ¬\n",
      "é¦–å…ˆ ç¯å¢ƒ åªèƒ½ ç®— ä¸­ç­‰ ï¼Œ å…¶æ¬¡ éœ¸ç‹é¤ æä¾› çš„ èœå“ ä¹Ÿ ä¸æ˜¯ å¾ˆå¤š ï¼Œ å½“ç„¶ å•†å®¶ ä¸ºäº† é¿å… å‚åŠ  éœ¸ç‹é¤ åƒä¸é¥± çš„ ç°è±¡ ï¼Œ ç»™ æ¯æ¡Œ éƒ½ æä¾› äº† è‡³å°‘ å…­ä»½ ä¸»é£Ÿ ï¼Œ æˆ‘ä»¬ é‚£æ¡Œ éƒ½ æä¾› äº† ä¸¤ä»½ å¹´ç³• ï¼Œ ç¬¬ä¸€æ¬¡ åƒç«é”… ä¼š åœ¨ æ¡Œä¸Š æœ‰ è¿™ä¹ˆ å¤š çš„ ä¸»é£Ÿ äº†\n",
      "æ•´ä½“ æ¥è¯´ è¿™å®¶ ç«é”…åº— æ²¡æœ‰ ä»€ä¹ˆ ç‰¹åˆ« æœ‰ ç‰¹è‰² çš„ ï¼Œ ä¸è¿‡ æ¯ä»½ èœå“ åˆ†é‡ è¿˜æ˜¯ æ¯”è¾ƒ è¶³ çš„ ï¼Œ è¿™ç‚¹ è¦ è‚¯å®š ï¼ è‡³äº ä»·æ ¼ ï¼Œ å› ä¸º æ²¡æœ‰ çœ‹ èœå• ä¸ äº†è§£ ï¼Œ ä¸è¿‡ æˆ‘ çœ‹ å¤§ä¼— æœ‰ è¿™å®¶ åº— çš„ å›¢è´­ ä»£é‡‘åˆ¸ ï¼Œ ç›¸å½“äº 7 æŠ˜ ï¼Œ åº”è¯¥ ä»·ä½ ä¸ä¼š å¾ˆ é«˜ çš„ ï¼ æœ€å è¿˜æ˜¯ è¦ æ„Ÿè°¢ å•†å®¶ æä¾› éœ¸ç‹é¤ ï¼Œ ç¥ ç”Ÿæ„å…´éš† ï¼Œ è´¢æº å¹¿è¿›\n"
     ]
    }
   ],
   "source": [
    "content_to_corpus(train_data_path, 'data/text_train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-15 02:39:32,887 [INFO] Read cache data/train/sentiment_analysis_trainingset.csv.segged_sample_None.tsv..\n"
     ]
    }
   ],
   "source": [
    "content_to_corpus(train_data_path, 'data/text_train_10k.txt',\n",
    "                  sample_n=10000, print_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-15 02:39:37,706 [INFO] Read cache data/validate/sentiment_analysis_validationset.csv.segged_sample_None.tsv..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å“ ï¼Œ æƒ³å½“å¹´ æ¥ ä½˜å±± çš„ æ—¶å€™ ï¼Œ å•¥ éƒ½ æ²¡æœ‰ ï¼Œ ä¸‰å“ é¦™ç®— é•‡ä¸Š æœ€å¤§ çœ‹èµ·æ¥ æœ€ åƒæ · çš„ é¥­åº— äº†\n",
      "èœå“ å¤š ï¼Œ æœ‰ç‚¹ å¤ª å¤š ï¼Œ æ„Ÿè§‰ å•¥ éƒ½ æœ‰ ï¼Œ æ‚éƒ½ ä¸è¶³ä»¥ å½¢å®¹\n",
      "éšä¾¿ ç‚¹äº› ï¼Œ å±…ç„¶ å£å‘³ ä»€ä¹ˆ çš„ éƒ½ å¥½ è¿˜ å¯ä»¥ ï¼Œ ä»·é’± è‡ªç„¶ æ˜¯ ä¾¿å®œ å½“ éœ‡æƒŠ\n",
      "å…ƒå® è™¾ å’Œ æ¤’ç› ä¹è‚šé±¼ éƒ½ ä¸é”™ åƒ\n",
      "ä¸è¿‡ è¿‘æ¥ å‡ æ¬¡ ä¹ˆ ï¼Œ å‘³é“ æ˜æ˜¾ æ²¡ ä»¥å‰ å¥½ äº†\n",
      "å†·é¤ é‡Œé¢ ä¸€ä¸ª å‡‰æ‹Œ æµ·å¸¦ä¸ è¿˜ å¯ä»¥ ï¼Œ é…¸é…¸ç”œç”œ çš„\n",
      "é•‡ä¸Š ä¹Ÿ æœ‰ äº† äº› åˆ«çš„ å¤§ç‚¹ çš„ é¥­åº— ï¼Œ æ‰€ä»¥ ä¸æ˜¯ æ¯æ¬¡ å¿…æ¥ äº†\n",
      "å¯¹ äº† ï¼Œ è¿™å®¶ çš„ ç”Ÿæ„ ä¸€å¦‚æ—¢å¾€ çš„ è¶…çº§ å¥½ ï¼Œ ä¸ å®šä½ åŸºæœ¬ åƒ ä¸åˆ°\n",
      "ä¸è¿‡ ä½˜å±± è¿™è¾¹ çš„ äºº åƒæ™šé¥­ å¾ˆæ—© çš„ ï¼Œ æ‰€ä»¥ ç¨å¾® æ™šç‚¹ å» å°± å¾ˆ ç©º äº†\n",
      "è¶ç€ å›½åº†èŠ‚ ï¼Œ ä¸€å®¶äºº åœ¨ ç™½å¤© åœ¨ å±±é‡Œ ç©è€ ä¹‹å ï¼Œ æ™šä¸Š å†³å®š åƒ æè®° æ…å›¢\n"
     ]
    }
   ],
   "source": [
    "content_to_corpus(validate_data_path, 'data/text_valid.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-15 02:39:42,945 [INFO] Read cache data/test-a/sentiment_analysis_testa.csv.segged_sample_None.tsv..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æˆ‘ æƒ³ è¯´ ä»–ä»¬ å®¶ çš„ ä¼˜æƒ æ´»åŠ¨ å¥½ æŒä¹… å•Š ï¼Œ æˆ‘ é¢„å”® çš„ æ—¶å€™ ä¹° çš„ åˆ¸ ï¼Œ å‰ä¸¤å¤© å¿ƒè¡€æ¥æ½® å» åƒ çš„ æ´»åŠ¨ è¿˜ åœ¨ ç»§ç»­\n",
      "é¦–å…ˆ è¯´ ä¸‹ æœåŠ¡ ï¼Œ å› ä¸º å’Œ ç”·ç¥¨ å¼€è½¦ å» çš„ ï¼Œ æœ‰ç‚¹ ä¸ è®¤è·¯ ï¼Œ è€æ¿ å¾ˆ è€å¿ƒ çš„ åœ¨ ç”µè¯ é‡Œ å¸® æˆ‘ä»¬ æŒ‡è·¯ ï¼Œ åˆ° äº† é—¨åº— ä¹‹å ä¹Ÿ å¸® æˆ‘ä»¬ æ¨è äº† ä»–ä»¬ å®¶ åš çš„ æ¯”è¾ƒ åœ°é“ çš„ ä¼¤å¿ƒ å‡‰ç²‰ ï¼Œ è¯´ æ˜¯ å¨å¸ˆ æ˜¯ å››å· é‚£è¾¹ æ¥ çš„\n",
      "ç¯å¢ƒ å‘¢ æ¯”è¾ƒç®€å• å¹²å‡€ ï¼Œ å» çš„ æ—¶å€™ ä¸‹åˆ ä¸€ç‚¹å¤š äº† ï¼Œ è¿˜æœ‰ å››äº”æ¡Œ äºº åœ¨ ç”¨é¤\n",
      "å£å‘³ å¯¹äº æˆ‘ è€Œè¨€ ç‚¹ äº† éº»è¾£ çš„ å£æ„Ÿ æ­£ æ­£å¥½ ï¼Œ ç”·ç¥¨ æ¯”è¾ƒ èƒ½ åƒ è¾£ ï¼Œ ç›¸å¯¹è€Œè¨€ è§‰å¾— ä»–ä»¬ å®¶ çš„ éº»è¾£ å£æ„Ÿ éº»æœ‰ äº† ï¼Œ è¾£ è¿˜ æ¬ ç¼º ä¸€ç‚¹ ï¼Œ è€æ¿å¨˜ è¯´ è€ƒè™‘ åˆ° å®¢äºº å£å‘³ ä¸åŒ æ‰€ä»¥ æ²¡æ•¢ æ”¾å¤ªå¤š è¾£æ¤’ ï¼Œ èƒ½ åƒ è¾£ çš„ æœ‹å‹ å¯ä»¥ è€ƒè™‘ ä¸‹å• ä¹‹å‰ å’Œ è€æ¿ å…ˆ è¯´å¥½\n",
      "é±¼ å‘¢ æˆ‘ä»¬ é€‰ çš„ æ˜¯ é»‘é±¼ ï¼Œ 2.9 æ–¤ çš„ é±¼ åŠ ä¸Š ä¸€ç›† æˆ‘ ä»¥ä¸º æ²¡æœ‰ ä»€ä¹ˆ ä¸œè¥¿ å®é™…ä¸Š ä¸œè¥¿ å¾ˆå¤š çš„ é”…åº• ï¼Œ æˆ‘ä»¬ åƒ çš„ é¥±é¥± çš„ ï¼Œ æœ€å ä»¥ä¸º åƒ çš„ å·®ä¸å¤š äº† ï¼Œ æ‰“åŒ… ä¸€çœ‹ ç®€ç›´ åƒ æ²¡åŠ¨ è¿‡ ä¸€æ · ï¼Œ åˆ†é‡ è¿˜æ˜¯ æ»¡è¶³ çš„ ï¼Œ é±¼ æ¯”è¾ƒ æ–°é²œ\n",
      "ä¼¤å¿ƒ å‡‰ç²‰ å¾ˆè¾£ ï¼Œ ä¸è¿‡ å£å‘³ ä¹Ÿ è›® å¥½åƒ çš„\n",
      "æ€»çš„æ¥è¯´ ï¼Œ æ€§ä»·æ¯” è¿˜æ˜¯ å¯ä»¥ çš„ ï¼Œ ä¸¤ä¸ª äºº åƒ äº† å¤§æ¦‚ 160 å·¦å³ ï¼Œ ç”¨ äº† å›¢è´­ åˆ¸ çš„è¯ ä¸€ç™¾å— ä¸åˆ° ï¼Œ ä¼š è€ƒè™‘ ä¸‹æ¬¡ å† æ¥\n",
      "ç»ˆäº å¼€ åˆ° å¿ƒå¿ƒå¿µå¿µ çš„ LAB BBLANKK loft\n",
      "ç¬¬ä¸€æ¬¡ æ¥ å°± éšä¾¿ ç‚¹ ä¹Ÿ ä¸€äº› ï½ ã€ é¦™è¾£è™¾ æ„ é¢ ã€‘ è›®è¾£ çš„ ï¼Œ ä½† å…¶å® ä¸€èˆ¬èˆ¬\n",
      "ã€ ç›æ ¼ä¸½ç‰¹ ã€‘ è¿›å£ çš„ æ„Ÿè§‰ è›® å¥½ çš„ å°±æ˜¯ å–å®Œ å å°± ç‚¹ å‘› ï½ ä½†æ˜¯ æœ‹å‹ ä¸æ˜¯ å¾ˆ å–œæ¬¢ ã€ ä¸€æŸ±æ“å¤© ã€‘ çœ‹ ç‚¹è¯„ å¾ˆå¤š äºº è¯´ å–œæ¬¢ å°± ç‚¹ äº† ï¼Œ æ°´èœœæ¡ƒ å‘³ ï¼Œ è¿˜ ä¸é”™ æŒº å¥½å– çš„ ï½ èµ ã€ æµ·é²œ é¥­ ã€‘ æƒ³ åƒé¥­ ä½† è¿™åº— çš„ é¥­ç±» åªæœ‰ ä¸¤ç§ ï¼Œ å°± ç‚¹ äº† è¿™ä¸ª\n"
     ]
    }
   ],
   "source": [
    "content_to_corpus(testa_data_path, 'data/text_testa.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-15 02:39:47,189 [INFO] Reading data/test-b/sentiment_analysis_testb.csv..\n",
      "2018-11-15 02:39:50,189 [INFO] Segmenting data/test-b/sentiment_analysis_testb.csv..\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200000/200000 [07:57<00:00, 419.20it/s]\n",
      "2018-11-15 02:47:51,128 [INFO] Saved cached data/test-b/sentiment_analysis_testb.csv.segged_sample_None.tsv.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¯ä»¥ è¯´ å·¥ä½œæ—¥ ä¸­åˆ çš„ è¿™ä¸ª å¥—é¤ ç€å® æ˜¯ ç‰¹åˆ« çš„ å®æƒ  å•Š ï¼Œ åº—å®¶ ç»™ çš„ é‡ ä¹Ÿ æ˜¯ å¤§å¤§çš„ è¶³ ï¼ é¦–å…ˆ å¦‚å›¾ ï¼Œ æ¯ä¸ª èœå“ æ‘†ç›˜ éƒ½ å¾ˆ ç²¾ç¾ ï¼Œ è®© äºº ä¸€ çœ‹ å°± å……æ»¡ é£Ÿæ¬²\n",
      "åœŸè±†æ³¥ å£å‘³ å¾ˆæ£’ ï¼Œ ç”œ é…±æ²¹ ã€ é±¼ç±½ å’Œ æ²™æ‹‰é…± çš„ æ­é… éå¸¸ å®Œç¾\n",
      "ä¸‰æ–‡é±¼ å¾ˆ æ–°é²œ ï¼Œ åˆ‡å¾— å¾— å¥½ åš å•Š ï¼Œ åƒ èµ·æ¥ éå¸¸ æ»¡è¶³ ï¼ çŒªæ’ é¥­ä¸Š çš„ å®åœ¨ æœ‰ç‚¹ æ…¢ äº† ï¼Œ è‡³å°‘ ç­‰ äº† 20 åˆ†é’Ÿ ï¼Œ ä½†é‡ è¶…çº§ å¤§ ï¼Œ ä¸Šé¢ æ˜¯ åˆ å¤§ åˆ åš çš„ ç‚¸ çŒªæ’ ï¼Œ ä¸ çŸ¥é“ æ˜¯ä¸æ˜¯ åšå¥½ äº† æ²¡æœ‰ åŠæ—¶ ç»™ ä¸Š ï¼Œ çŒªæ’ å·²ç» è¢« é…±æ± æ³¡å¾—å˜ æ¹¿è½¯ äº† ï¼Œ æ²¡æœ‰ äº† é…¥è„† æ„Ÿ\n",
      "è¿™ä¸ª å¥—é¤ åº—å®¶ çœŸçš„ æ˜¯ æ»¡æ»¡çš„ è¯šæ„ å•Š ï¼Œ ä¼°è®¡ ä¸€èˆ¬ äºº çœŸçš„ åƒä¸å®Œ\n",
      "ä½ç½® å¾ˆ ä¸é”™ ï¼Œ è€æ¿ çœ¼å…‰ å¾ˆ å¥½ ğŸ‘\n",
      "ä½äº åœ°é“ç«™ é™„è¿‘ ï¼Œ å‘¨å›´ æœ‰ åŠå…¬æ¥¼ ã€ å•†åœˆ ã€ ä½å®… ã€ åˆ«å¢… è™½ç„¶ ç°åœ¨ è¿˜ æœ‰äº› è’å‡‰ ï¼Œ ä½† æˆ‘ æƒ³ å¾ˆå¿« ä¼š å‘å±• èµ·æ¥ çš„ ğŸ’ª\n",
      "é¤å… å†…éƒ¨ çš„ ç¯å¢ƒ è¿˜ ç®— å¹²å‡€ æ¸©é¦¨\n",
      "æœåŠ¡å‘˜ ä¹Ÿ å¾ˆ çƒ­æƒ… äº²åˆ‡\n",
      "å§œæ²¹å¤§ èŠ¥èœ ï¼š é¦–å…ˆ çœ‹åˆ° è§‰å¾— ç•¥å¾® ç²—æ—· äº† äº› ï¼Œ ä½† åƒ èµ·æ¥ å‘³é“ ä¸é”™ ï¼Œ å§œä¸ æ²¡æœ‰ å¾ˆ æµ“é‡ çš„ å‘³é“\n",
      "é¦™ç…æµ· é²ˆé±¼ ï¼š ç‰¹åˆ« é…¥è„† é²œé¦™ å¥½åƒ ğŸ˜‹\n"
     ]
    }
   ],
   "source": [
    "content_to_corpus(testb_data_path, 'data/text_testb.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2896571 76231079 412681013 data/text_all.txt\r\n"
     ]
    }
   ],
   "source": [
    "!cat data/text_train.txt data/text_valid.txt data/text_testa.txt data/text_testb.txt > data/text_all.txt\n",
    "!wc data/text_all.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All dataset combined has 76 million words, which is too many. According to [ELMoForManyLangs](https://github.com/HIT-SCIR/ELMoForManyLangs), it would take 3 days to train 20m words on an NVIDIA P100 GPU.\n",
    "\n",
    "We must sample the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   82727 2255688 12200210 data/text_train_10k.txt\r\n"
     ]
    }
   ],
   "source": [
    "!wc data/text_train_10k.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A random sample of 10,000 reviews gives about 83k sentences, and 2.2m words.\n",
    "It should take probably 8 hours to train the embedings from the 10,000 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åº—é‡Œ å†°æ·‡æ·‹ æœ‰ 12 ä¸ª å£å‘³ çš„ ~\r\n",
      "é™¤äº† å†°æ·‡æ·‹ ~ ç”œå“ é¥®æ–™ ä¹Ÿ æœ‰ ~ çœ‹ ç”µå½± å‰ å¯ä»¥ æ¥ è¿™é‡Œ ç­‰ ~ ä¹Ÿ å¯ä»¥ ä¹° è¿›å» åƒ å“ˆ ~\r\n",
      "# æ«æ ‘ èƒ¡æ¡ƒ # BBLANKK\r\n",
      "åº—å‘˜ å¦¹å­ æŒ– å®Œ å†°æ·‡æ·‹ è¿˜ å¸® æˆ‘ ç§° äº† ä¸€ä¸‹ ~ è¯´ ä»–ä»¬ å®¶ çš„ å•çƒ æ˜¯ 60g ~\r\n",
      "å‘³é“ å¾ˆ å¥½ å•Š ~ å¥¶å‘³ç®—é‡ çš„ äº† ~ ä¹Ÿ ä¸ä¼š å¾ˆç”œ ~ é‡Œé¢ æœ‰ æ ¸æ¡ƒä» ~ æ ¸æ¡ƒä» ä¹Ÿ å¥½åƒ ~\r\n",
      "ä¸€ä¸ª çƒæŒº å¤š çš„ ~ åƒ ç€ ç»å¯¹ å¤Ÿ äº† ~\r\n",
      "ä¸è¿‡ åŸä»· æœ‰ç‚¹ å°è´µ ~ M å›¢æœ‰ å›¢è´­ èƒ½ ä¾¿å®œ ä¸€ç‚¹ ~\r\n",
      "æ€»ä½“ å¾ˆ æ»¡æ„ çš„ ~ ä»¥å æƒ³ åƒ å†°æ·‡æ·‹ å¯ä»¥ æ¥ è¿™å®¶ ~ å† åƒ åƒ åˆ«çš„ å‘³ ~\r\n",
      "æé£Ÿ urban BBLANKK harvest æ˜¯ ä¸€ä¸ª èµ° è‡ªç„¶ ç¯ä¿ é«˜ç«¯ çº¿è·¯ çš„ é¤å… ï¼Œ ä½äº æ­å· å¤§å¦ Dåº§ 5 æ¥¼ ï½ å…‰çœ‹ åœ°æ ‡ ä¹Ÿ æ˜¯ å¤Ÿ é€¼æ ¼ äº† ä¸€è¿› é—¨å£ è£…é¥° æœ‰ å¾®å‹ ç”°å›­ BBLANKK çœ‹ä¸Šå» é£Ÿæ éƒ½ æ–°é²œ çš„ ä¸è¦ ä¸è¦ çš„ ï½ ç»™ åˆ›æ„ ä¸€ä¸ª èµ BBLANKK åªè¦ èœå• ä¸Š æœ‰ â€œ å³ æ‘˜ â€ å­—çœ¼ çš„ ï¼Œ éƒ½ ç”± æœåŠ¡å‘˜ ç°åœº é‡‡æ‘˜ å–ç”¨ ï¼Œ èœè‰² æ‘†ç›˜ ç²¾è‡´ è€Œä¸” è‰²å½© ä¸°å¯Œ ï¼Œ è®© äºº é£Ÿæ¬² å¤§å¼€ ï¼Œ å£å‘³ éƒ½ è¿˜ ä¸é”™ ï½ ä¸è¿‡ æœ¬äºº æœ¬ å°± ä¸æ˜¯ ä¸€ä¸ª å¤ª æŒ‘é£Ÿ çš„ äºº å•¦ é¥­å ä¸Š äº† ç”œå“ ï¼Œ å¥½åƒ åˆ° é£ èµ·æ¥ ï¼Œ åƒ å¾— æ„‰å¿« å¿ƒæƒ… å°± å¥½å¥½ ï¼Œ å°¤å…¶ æ˜¯ è¿™æ · ä¸€ä¸ª å‘¨æœ«\r\n",
      "å› ä¸º ä»·æ ¼ åè´µ çš„ ç¼˜æ•… ï¼Œ å¦‚æ­¤ é»„é‡‘åœ°æ®µ ã€ é«˜å³° æ—¶é—´ ç”¨é¤ äºº å€’ ä¸ å¤š ï¼Œ è¿™ ä¹Ÿ ä¿è¯ äº† ç”¨é¤ ç¯å¢ƒ çš„ èˆ’é€‚åº¦ ï¼Œ è¿˜æœ‰ ä¸€ä¸ª å¥½æ¶ˆæ¯ å°±æ˜¯ ï¼š å¼€ä¸š åˆæœŸ æœ‰ ä¸ƒæŠ˜ ä¼˜æƒ  å“¦ ï¼ å¤§å®¶ èµ¶ç´§ å» æ‹”è‰ å§\r\n"
     ]
    }
   ],
   "source": [
    "!tail data/text_train_10k.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Let's try a very small subset just to make sure the software works.\n",
    "\n",
    "Use 1000 sentences as training and 100 sentences as validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1000   27705  150876 data/text_train_1ks.txt\n",
      "     100    2729   14924 data/text_train_100s.txt\n"
     ]
    }
   ],
   "source": [
    "# !shuf -n 10000 data/all_text.txt > data/little_text.txt\n",
    "# Use `gshuf` on Mac\n",
    "!gshuf -n 1000 data/text_train.txt > data/text_train_1ks.txt\n",
    "!gshuf -n 100 data/text_train.txt > data/text_train_100s.txt\n",
    "!wc data/text_train_1ks.txt\n",
    "!wc data/text_train_100s.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, clip_grad=5.0, config_path='/Users/jesse/workspace/ML/fine-grain-sentiment-analysis/misc/elmo/cnn_50_100_512_4096_sample.json', eval_steps=10000, gpu=0, lr=0.001, lr_decay=0.8, max_epoch=10, max_sent_len=20, max_vocab_size=150000, min_count=5, model='data/elmo-zhs-1k', optimizer='adam', save_classify_layer=False, seed=1, test_path=None, train_path='data/text_train_100s.txt', valid_path=None, valid_size=10, word_embedding=None)\n",
      "{'encoder': {'name': 'elmo', 'projection_dim': 512, 'cell_clip': 3, 'proj_clip': 3, 'dim': 4096, 'n_layers': 2}, 'token_embedder': {'name': 'cnn', 'activation': 'relu', 'filters': [[1, 32], [2, 32], [3, 64], [4, 128], [5, 256], [6, 512], [7, 1024]], 'n_highway': 2, 'word_dim': 100, 'char_dim': 50, 'max_characters_per_token': 50}, 'classifier': {'name': 'sampled_softmax', 'n_samples': 8192}, 'dropout': 0.1}\n",
      "2018-11-15 03:06:43,847 INFO: training instance: 149, training tokens: 2836.\n",
      "2018-11-15 03:06:43,847 INFO: training instance: 139, training tokens after division: 2646.\n",
      "2018-11-15 03:06:43,847 INFO: valid instance: 10, valid tokens: 190.\n",
      "2018-11-15 03:06:43,850 INFO: Truncated word count: 1359.\n",
      "2018-11-15 03:06:43,850 INFO: Original vocabulary size: 1090.\n",
      "2018-11-15 03:06:43,851 INFO: Word embedding size: 78\n",
      "2018-11-15 03:06:43,853 INFO: Char embedding size: 902\n",
      "2018-11-15 03:06:44,055 INFO: 5 batches, avg len: 20.0\n",
      "2018-11-15 03:06:44,056 INFO: Evaluate every 10000 batches.\n",
      "2018-11-15 03:06:44,067 INFO: 1 batches, avg len: 20.0\n",
      "2018-11-15 03:06:44,067 INFO: vocab size: 78\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "2018-11-15 03:06:49,848 INFO: Model(\n",
      "  (token_embedder): ConvTokenEmbedder(\n",
      "    (word_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(78, 100, padding_idx=3)\n",
      "    )\n",
      "    (char_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(902, 50, padding_idx=899)\n",
      "    )\n",
      "    (convolutions): ModuleList(\n",
      "      (0): Conv1d(50, 32, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(50, 32, kernel_size=(2,), stride=(1,))\n",
      "      (2): Conv1d(50, 64, kernel_size=(3,), stride=(1,))\n",
      "      (3): Conv1d(50, 128, kernel_size=(4,), stride=(1,))\n",
      "      (4): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
      "      (5): Conv1d(50, 512, kernel_size=(6,), stride=(1,))\n",
      "      (6): Conv1d(50, 1024, kernel_size=(7,), stride=(1,))\n",
      "    )\n",
      "    (highways): Highway(\n",
      "      (_layers): ModuleList(\n",
      "        (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "        (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (projection): Linear(in_features=2148, out_features=512, bias=True)\n",
      "  )\n",
      "  (encoder): ElmobiLm(\n",
      "    (forward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (forward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      "  (classify_layer): SampledSoftmaxLayer(\n",
      "    (criterion): CrossEntropyLoss()\n",
      "    (column_emb): Embedding(78, 512)\n",
      "    (column_bias): Embedding(78, 1)\n",
      "  )\n",
      ")\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/elmoformanylangs-0.0.2-py3.6.egg/elmoformanylangs/biLM.py:343: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/elmoformanylangs-0.0.2-py3.6.egg/elmoformanylangs/biLM.py:348: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/elmoformanylangs-0.0.2-py3.6.egg/elmoformanylangs/biLM.py:297: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "2018-11-15 03:06:55,393 INFO: Epoch=0 iter=5 lr=0.001000 valid_ppl=72.815895\n",
      "2018-11-15 03:06:55,994 INFO: New record achieved!\n",
      "2018-11-15 03:06:58,477 INFO: Epoch=1 iter=5 lr=0.000800 valid_ppl=38.599525\n",
      "2018-11-15 03:06:59,102 INFO: New record achieved!\n",
      "2018-11-15 03:07:01,467 INFO: Epoch=2 iter=5 lr=0.000640 valid_ppl=14.500859\n",
      "2018-11-15 03:07:02,077 INFO: New record achieved!\n",
      "2018-11-15 03:07:05,598 INFO: Epoch=3 iter=5 lr=0.000512 valid_ppl=11.034621\n",
      "2018-11-15 03:07:06,522 INFO: New record achieved!\n",
      "2018-11-15 03:07:08,950 INFO: Epoch=4 iter=5 lr=0.000410 valid_ppl=11.360459\n",
      "2018-11-15 03:07:11,265 INFO: Epoch=5 iter=5 lr=0.000328 valid_ppl=8.874183\n",
      "2018-11-15 03:07:11,868 INFO: New record achieved!\n",
      "2018-11-15 03:07:14,915 INFO: Epoch=6 iter=5 lr=0.000262 valid_ppl=8.629713\n",
      "2018-11-15 03:07:15,532 INFO: New record achieved!\n",
      "2018-11-15 03:07:17,992 INFO: Epoch=7 iter=5 lr=0.000210 valid_ppl=8.306626\n",
      "2018-11-15 03:07:18,607 INFO: New record achieved!\n",
      "2018-11-15 03:07:20,959 INFO: Epoch=8 iter=5 lr=0.000168 valid_ppl=8.456163\n",
      "2018-11-15 03:07:23,581 INFO: Epoch=9 iter=5 lr=0.000134 valid_ppl=8.405726\n",
      "2018-11-15 03:07:23,584 INFO: best train ppl: 100000000.000000, best valid ppl: 8.306626.\n"
     ]
    }
   ],
   "source": [
    "!python -m elmoformanylangs.biLM train \\\n",
    "    --train_path data/text_train_100s.txt \\\n",
    "    --model data/elmo-zhs-1k \\\n",
    "    --valid_size 10 \\\n",
    "    --config_path `pwd`/misc/elmo/cnn_50_100_512_4096_sample.json \\\n",
    "    --seed 1 \\\n",
    "    --gpu 0 \\\n",
    "    --optimizer adam \\\n",
    "    --lr 0.001 \\\n",
    "    --lr_decay 0.8 \\\n",
    "    --batch_size 32 \\\n",
    "    --clip_grad 5 \\\n",
    "    --max_epoch 10 \\\n",
    "    --max_sent_len 20 \\\n",
    "    --max_vocab_size 150000 \\\n",
    "    --eval_steps 10000 \\\n",
    "    --min_count 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, clip_grad=5.0, config_path='/Users/jesse/workspace/ML/fine-grain-sentiment-analysis/misc/elmo/cnn_50_100_512_4096_sample.json', eval_steps=10000, gpu=0, lr=0.001, lr_decay=0.8, max_epoch=10, max_sent_len=20, max_vocab_size=150000, min_count=5, model='data/elmo-zhs-1k', optimizer='adam', save_classify_layer=False, seed=1, test_path=None, train_path='data/text_train_1k.txt', valid_path='data/text_train_100.txt', valid_size=0, word_embedding=None)\n",
      "{'encoder': {'name': 'elmo', 'projection_dim': 512, 'cell_clip': 3, 'proj_clip': 3, 'dim': 4096, 'n_layers': 2}, 'token_embedder': {'name': 'cnn', 'activation': 'relu', 'filters': [[1, 32], [2, 32], [3, 64], [4, 128], [5, 256], [6, 512], [7, 1024]], 'n_highway': 2, 'word_dim': 100, 'char_dim': 50, 'max_characters_per_token': 50}, 'classifier': {'name': 'sampled_softmax', 'n_samples': 8192}, 'dropout': 0.1}\n",
      "2018-11-14 22:36:57,640 INFO: training instance: 1505, training tokens: 28596.\n",
      "2018-11-14 22:36:57,645 INFO: valid instance: 143, valid tokens: 2705.\n",
      "2018-11-14 22:36:57,675 INFO: Truncated word count: 7085.\n",
      "2018-11-14 22:36:57,676 INFO: Original vocabulary size: 5629.\n",
      "2018-11-14 22:36:57,683 INFO: Word embedding size: 786\n",
      "2018-11-14 22:36:57,704 INFO: Char embedding size: 2140\n",
      "2018-11-14 22:36:59,727 INFO: 48 batches, avg len: 20.0\n",
      "2018-11-14 22:36:59,728 INFO: Evaluate every 10000 batches.\n",
      "2018-11-14 22:37:00,040 INFO: 5 batches, avg len: 19.9\n",
      "2018-11-14 22:37:00,040 INFO: vocab size: 786\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "2018-11-14 22:37:08,984 INFO: Model(\n",
      "  (token_embedder): ConvTokenEmbedder(\n",
      "    (word_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(786, 100, padding_idx=3)\n",
      "    )\n",
      "    (char_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(2140, 50, padding_idx=2137)\n",
      "    )\n",
      "    (convolutions): ModuleList(\n",
      "      (0): Conv1d(50, 32, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(50, 32, kernel_size=(2,), stride=(1,))\n",
      "      (2): Conv1d(50, 64, kernel_size=(3,), stride=(1,))\n",
      "      (3): Conv1d(50, 128, kernel_size=(4,), stride=(1,))\n",
      "      (4): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
      "      (5): Conv1d(50, 512, kernel_size=(6,), stride=(1,))\n",
      "      (6): Conv1d(50, 1024, kernel_size=(7,), stride=(1,))\n",
      "    )\n",
      "    (highways): Highway(\n",
      "      (_layers): ModuleList(\n",
      "        (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "        (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (projection): Linear(in_features=2148, out_features=512, bias=True)\n",
      "  )\n",
      "  (encoder): ElmobiLm(\n",
      "    (forward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (forward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      "  (classify_layer): SampledSoftmaxLayer(\n",
      "    (criterion): CrossEntropyLoss()\n",
      "    (column_emb): Embedding(786, 512)\n",
      "    (column_bias): Embedding(786, 1)\n",
      "  )\n",
      ")\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/elmoformanylangs-0.0.2-py3.6.egg/elmoformanylangs/biLM.py:343: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/elmoformanylangs-0.0.2-py3.6.egg/elmoformanylangs/biLM.py:348: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "2018-11-14 22:37:40,645 INFO: Epoch=0 iter=32 lr=0.001000 train_ppl=72388.250000 time=28.90s\n",
      "/Users/jesse/anaconda3/envs/idp/lib/python3.6/site-packages/elmoformanylangs-0.0.2-py3.6.egg/elmoformanylangs/biLM.py:297: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "2018-11-14 22:37:56,929 INFO: Epoch=0 iter=48 lr=0.001000 valid_ppl=58.615864\n",
      "2018-11-14 22:37:57,981 INFO: New record achieved!\n",
      "2018-11-14 22:38:24,576 INFO: Epoch=1 iter=32 lr=0.000800 train_ppl=63.343208 time=26.59s\n",
      "2018-11-14 22:38:42,185 INFO: Epoch=1 iter=48 lr=0.000800 valid_ppl=44.460205\n",
      "2018-11-14 22:38:42,798 INFO: New record achieved!\n",
      "2018-11-14 22:39:09,410 INFO: Epoch=2 iter=32 lr=0.000640 train_ppl=52.716682 time=26.61s\n",
      "2018-11-14 22:39:24,734 INFO: Epoch=2 iter=48 lr=0.000640 valid_ppl=41.916843\n",
      "2018-11-14 22:39:25,305 INFO: New record achieved!\n",
      "2018-11-14 22:39:55,008 INFO: Epoch=3 iter=32 lr=0.000512 train_ppl=47.527332 time=29.70s\n",
      "2018-11-14 22:40:11,341 INFO: Epoch=3 iter=48 lr=0.000512 valid_ppl=39.813450\n",
      "2018-11-14 22:40:12,012 INFO: New record achieved!\n",
      "2018-11-14 22:40:38,603 INFO: Epoch=4 iter=32 lr=0.000410 train_ppl=43.219276 time=26.58s\n",
      "2018-11-14 22:40:54,555 INFO: Epoch=4 iter=48 lr=0.000410 valid_ppl=38.112942\n",
      "2018-11-14 22:40:55,184 INFO: New record achieved!\n",
      "2018-11-14 22:41:27,812 INFO: Epoch=5 iter=32 lr=0.000328 train_ppl=40.482231 time=32.62s\n",
      "2018-11-14 22:41:44,222 INFO: Epoch=5 iter=48 lr=0.000328 valid_ppl=37.239307\n",
      "2018-11-14 22:41:44,942 INFO: New record achieved!\n",
      "2018-11-14 22:42:12,696 INFO: Epoch=6 iter=32 lr=0.000262 train_ppl=36.799458 time=27.75s\n",
      "2018-11-14 22:42:29,051 INFO: Epoch=6 iter=48 lr=0.000262 valid_ppl=36.741238\n",
      "2018-11-14 22:42:29,662 INFO: New record achieved!\n",
      "2018-11-14 22:42:58,419 INFO: Epoch=7 iter=32 lr=0.000210 train_ppl=35.172501 time=28.75s\n",
      "2018-11-14 22:43:17,635 INFO: Epoch=7 iter=48 lr=0.000210 valid_ppl=36.912933\n",
      "2018-11-14 22:43:48,403 INFO: Epoch=8 iter=32 lr=0.000168 train_ppl=32.478752 time=30.75s\n",
      "2018-11-14 22:44:03,723 INFO: Epoch=8 iter=48 lr=0.000168 valid_ppl=36.847874\n",
      "2018-11-14 22:44:29,567 INFO: Epoch=9 iter=32 lr=0.000134 train_ppl=31.984341 time=25.84s\n",
      "2018-11-14 22:44:51,497 INFO: Epoch=9 iter=48 lr=0.000134 valid_ppl=37.348961\n",
      "2018-11-14 22:44:51,503 INFO: best train ppl: 100000000.000000, best valid ppl: 36.741238.\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "# add `pwd` to `config_path` because trained model depends on that file\n",
    "# absolute path makes it easier to find\n",
    "!python -m elmoformanylangs.biLM train \\\n",
    "    --train_path data/text_train_1ks.txt \\\n",
    "    --valid_path data/text_train_100s.txt \\\n",
    "    --model data/elmo-zhs-1k \\\n",
    "    --config_path `pwd`/misc/elmo/cnn_50_100_512_4096_sample.json \\\n",
    "    --seed 1 \\\n",
    "    --gpu 0 \\\n",
    "    --optimizer adam \\\n",
    "    --lr 0.001 \\\n",
    "    --lr_decay 0.8 \\\n",
    "    --batch_size 32 \\\n",
    "    --clip_grad 5 \\\n",
    "    --max_epoch 10 \\\n",
    "    --max_sent_len 20 \\\n",
    "    --max_vocab_size 150000 \\\n",
    "    --eval_steps 10000 \\\n",
    "    --min_count 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-14 23:19:31,908 [INFO] Read cache data/train/sentiment_analysis_trainingset.csv.segged_sample_None.tsv..\n"
     ]
    }
   ],
   "source": [
    "df_train = read_csv(train_data_path, seg_words=True, sample_n=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-14 23:21:26,090 [INFO] char embedding size: 8582\n",
      "2018-11-14 23:21:26,861 [INFO] word embedding size: 69827\n",
      "2018-11-14 23:21:34,862 [INFO] Model(\n",
      "  (token_embedder): ConvTokenEmbedder(\n",
      "    (word_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(69827, 100, padding_idx=3)\n",
      "    )\n",
      "    (char_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(8582, 50, padding_idx=8579)\n",
      "    )\n",
      "    (convolutions): ModuleList(\n",
      "      (0): Conv1d(50, 32, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(50, 32, kernel_size=(2,), stride=(1,))\n",
      "      (2): Conv1d(50, 64, kernel_size=(3,), stride=(1,))\n",
      "      (3): Conv1d(50, 128, kernel_size=(4,), stride=(1,))\n",
      "      (4): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
      "      (5): Conv1d(50, 512, kernel_size=(6,), stride=(1,))\n",
      "      (6): Conv1d(50, 1024, kernel_size=(7,), stride=(1,))\n",
      "    )\n",
      "    (highways): Highway(\n",
      "      (_layers): ModuleList(\n",
      "        (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "        (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (projection): Linear(in_features=2148, out_features=512, bias=True)\n",
      "  )\n",
      "  (encoder): ElmobiLm(\n",
      "    (forward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (forward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "2018-11-14 23:21:35,856 [INFO] 1 batches, avg len: 371.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.16197295,  0.05117923, -0.13360588, ...,  0.24924016,\n",
       "         -0.27383432, -0.05000202],\n",
       "        [ 0.06199374,  0.07696173, -0.23577517, ...,  0.26290917,\n",
       "         -0.27809614, -0.06464732],\n",
       "        [ 0.0008731 , -0.04712557, -0.08987609, ..., -0.00968068,\n",
       "         -0.13784361, -0.03070146],\n",
       "        ...,\n",
       "        [-0.27461815,  0.03719755, -0.13428287, ..., -0.06027537,\n",
       "         -0.07961495, -0.14139868],\n",
       "        [-0.06108154,  0.13908525, -0.2571093 , ...,  0.01645198,\n",
       "         -0.02265188, -0.02150639],\n",
       "        [-0.19907278,  0.02419554, -0.19596738, ...,  0.07171986,\n",
       "         -0.01507132,  0.02613006]], dtype=float32),\n",
       " array([[-0.17354196, -0.36698878, -0.04885902, ..., -0.02680009,\n",
       "          0.13608061,  0.12091058],\n",
       "        [-0.29550084, -0.12204532, -0.28084293, ..., -0.29321548,\n",
       "          0.13516046, -0.11846065],\n",
       "        [-0.05146622, -0.19961458,  0.01509347, ...,  0.05483557,\n",
       "         -0.06374971, -0.0203303 ],\n",
       "        ...,\n",
       "        [-0.1181826 ,  0.02767085, -0.35975978, ..., -0.01324531,\n",
       "          0.00909343, -0.03078758],\n",
       "        [-0.0251124 ,  0.20625134, -0.2706751 , ...,  0.09297368,\n",
       "          0.14488776, -0.00088627],\n",
       "        [-0.04889162, -0.19273376, -0.3477179 , ...,  0.0895622 ,\n",
       "          0.04090813,  0.11943939]], dtype=float32)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elmoformanylangs import Embedder\n",
    "\n",
    "elmoemb = Embedder('data/elmo-zhs-fsauor')\n",
    "# e = Embedder('data/elmo-zhs-1k')\n",
    "\n",
    "sents = df_train['content'][0:2]\n",
    "elmoemb.sents2elmo(sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now let's train the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2773187 72830536 394294246 data/text_train_testab.txt\n",
      "  123384 3400543 18386767 data/text_valid.txt\n"
     ]
    }
   ],
   "source": [
    "!cat data/text_train.txt data/text_testa.txt data/text_testb.txt > data/text_train_testab.txt\n",
    "!wc data/text_train_testab.txt\n",
    "!wc data/text_valid.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To train the full model\n",
    "!time python -m elmoformanylangs.biLM train \\\n",
    "    --train_path data/text_train_testab.txt \\\n",
    "    --valid_path data/text_valid.txt \\\n",
    "    --model data/elmo-zhs \\\n",
    "    --config_path `pwd`/misc/elmo/cnn_50_100_512_4096_sample.json \\\n",
    "    --seed 1 \\\n",
    "    --gpu 0 \\\n",
    "    --optimizer adam \\\n",
    "    --lr 0.001 \\\n",
    "    --lr_decay 0.8 \\\n",
    "    --batch_size 32 \\\n",
    "    --clip_grad 5 \\\n",
    "    --max_epoch 10 \\\n",
    "    --max_sent_len 20 \\\n",
    "    --max_vocab_size 150000 \\\n",
    "    --eval_steps 10000 \\\n",
    "    --min_count 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
